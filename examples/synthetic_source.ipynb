{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1652f7",
   "metadata": {},
   "source": [
    "# How to use `Source`?\n",
    "## Synthetic Data\n",
    "\n",
    "`tab2seq` package has a function that can generate synthetic datasets: `health`, `labour`, `income` and `survey`. Each of these has a unique data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab2seq.datasets import generate_synthetic_data\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fadc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = generate_synthetic_data(output_dir=\"synthetic_data\", \n",
    "                                     n_entities=10000, \n",
    "                                     seed=742, \n",
    "                                     registries=[\"health\", \"labour\", \"survey\", \"income\"],\n",
    "                                     file_format=\"parquet\")\n",
    "print(\"Generated synthetic data at:\", data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377b35a",
   "metadata": {},
   "source": [
    "You can use `polars` to load and look at these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_health = pl.read_parquet(data_paths[\"health\"])\n",
    "lf_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d70d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_labour = pl.read_parquet(data_paths[\"labour\"])\n",
    "lf_labour.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e15d4",
   "metadata": {},
   "source": [
    "## Sources\n",
    "A `Source` represents a data table(-s) of a specific event type. This could be a hospital admissions registry,\n",
    "an income registry, or a labor market record... you name it.\n",
    "\n",
    "Each `Source` stores the information needed to read and validate that table:\n",
    "1. where it lives on disk,\n",
    "2. which column identifies the entity (e.g. a person, firm, or object),\n",
    "3. which column holds the timestamp, and\n",
    "4. which columns carry categorical or continuous features.\n",
    "\n",
    "`Source` heavily relies on the `pydantic` configuration files: makes it straightforward to define new event types simply by writing \n",
    "a config, without touching any reading or validation logic.\n",
    "\n",
    "**Note**: `Source` makes the first filtering and preprocessing steps by removing rows with empty `enitity_ids` \n",
    "and rows with empty `timestamp_cols` (in case you specified these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2afe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab2seq.source import Source, SourceConfig, SourceCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fc417",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_H = Source(config=SourceConfig(\n",
    "    name=\"health\",\n",
    "    filepath=\"synthetic_data/health.parquet\",\n",
    "    entity_id_col=\"entity_id\",\n",
    "    categorical_cols=[\"diagnosis\", \"procedure\" , \"department\"],\n",
    "    continuous_cols=['cost', 'length_of_stay'],\n",
    "    output_format=\"parquet\",\n",
    "    timestamp_cols=[\"date\"]\n",
    "))\n",
    "\n",
    "print(\"Number of unique IDs:\", len(source_H.get_entity_ids()))\n",
    "source_H.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you could define the Source config separately and then create the Source\n",
    "\n",
    "config_L = SourceConfig(\n",
    "    name=\"labour\",\n",
    "    filepath=\"synthetic_data/labour.parquet\",\n",
    "    entity_id_col=\"entity_id\",\n",
    "    categorical_cols=[\"status\", \"occupation\", \"residence_region\"],\n",
    "    continuous_cols=['weekly_hours'],\n",
    "    output_format=\"parquet\",\n",
    "    timestamp_cols=[\"date\", \"birthday\"],\n",
    ")\n",
    "source_L = Source(config=config_L)\n",
    "\n",
    "print(\"Number of unique IDs:\", len(source_L.get_entity_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ae9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create a SourceCollection to manage multiple sources together\n",
    "collection = SourceCollection(sources=[source_H, source_L])\n",
    "\n",
    "\n",
    "print(\"All unique entity IDs in collection:\", len(collection.get_all_entity_ids()))\n",
    "#You can get access to the individual sources in the collection by running the following:\n",
    "collection.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6afc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab2seq-dev-mZHLrpIW-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
