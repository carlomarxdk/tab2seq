{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1652f7",
   "metadata": {},
   "source": [
    "# How to use `Source`?\n",
    "## Synthetic Data\n",
    "\n",
    "`tab2seq` package has a function that can generate synthetic datasets: `health`, `labour`, `income` and `survey`. Each of these has a unique data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5970bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab2seq.datasets import generate_synthetic_data\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5fadc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data at: {'health': PosixPath('synthetic_data/health.parquet'), 'labour': PosixPath('synthetic_data/labour.parquet'), 'survey': PosixPath('synthetic_data/survey.parquet'), 'income': PosixPath('synthetic_data/income.parquet')}\n"
     ]
    }
   ],
   "source": [
    "data_paths = generate_synthetic_data(output_dir=\"synthetic_data\", \n",
    "                                     n_entities=10000, \n",
    "                                     seed=742, \n",
    "                                     registries=[\"health\", \"labour\", \"survey\", \"income\"],\n",
    "                                     file_format=\"parquet\")\n",
    "print(\"Generated synthetic data at:\", data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377b35a",
   "metadata": {},
   "source": [
    "You can use `polars` to load and look at these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae32a281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>date</th><th>diagnosis</th><th>procedure</th><th>department</th><th>cost</th><th>length_of_stay</th></tr><tr><td>str</td><td>date</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;E00001&quot;</td><td>2016-09-15</td><td>&quot;J18.1&quot;</td><td>&quot;CABG&quot;</td><td>&quot;gastroenterology&quot;</td><td>7306.17</td><td>2</td></tr><tr><td>&quot;E00001&quot;</td><td>2017-05-25</td><td>&quot;E78.0&quot;</td><td>&quot;XRAY&quot;</td><td>&quot;neurology&quot;</td><td>138.65</td><td>1</td></tr><tr><td>&quot;E00001&quot;</td><td>2018-01-18</td><td>&quot;E78.0&quot;</td><td>&quot;MRI&quot;</td><td>&quot;general_surgery&quot;</td><td>6704.59</td><td>10</td></tr><tr><td>&quot;E00001&quot;</td><td>2019-11-11</td><td>&quot;C34.1&quot;</td><td>&quot;ECHO&quot;</td><td>&quot;general_surgery&quot;</td><td>910.12</td><td>0</td></tr><tr><td>&quot;E00001&quot;</td><td>2020-05-20</td><td>&quot;E78.0&quot;</td><td>&quot;DIALYSIS&quot;</td><td>&quot;neurology&quot;</td><td>2266.52</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌───────────┬────────────┬───────────┬───────────┬──────────────────┬─────────┬────────────────┐\n",
       "│ entity_id ┆ date       ┆ diagnosis ┆ procedure ┆ department       ┆ cost    ┆ length_of_stay │\n",
       "│ ---       ┆ ---        ┆ ---       ┆ ---       ┆ ---              ┆ ---     ┆ ---            │\n",
       "│ str       ┆ date       ┆ str       ┆ str       ┆ str              ┆ f64     ┆ i64            │\n",
       "╞═══════════╪════════════╪═══════════╪═══════════╪══════════════════╪═════════╪════════════════╡\n",
       "│ E00001    ┆ 2016-09-15 ┆ J18.1     ┆ CABG      ┆ gastroenterology ┆ 7306.17 ┆ 2              │\n",
       "│ E00001    ┆ 2017-05-25 ┆ E78.0     ┆ XRAY      ┆ neurology        ┆ 138.65  ┆ 1              │\n",
       "│ E00001    ┆ 2018-01-18 ┆ E78.0     ┆ MRI       ┆ general_surgery  ┆ 6704.59 ┆ 10             │\n",
       "│ E00001    ┆ 2019-11-11 ┆ C34.1     ┆ ECHO      ┆ general_surgery  ┆ 910.12  ┆ 0              │\n",
       "│ E00001    ┆ 2020-05-20 ┆ E78.0     ┆ DIALYSIS  ┆ neurology        ┆ 2266.52 ┆ 2              │\n",
       "└───────────┴────────────┴───────────┴───────────┴──────────────────┴─────────┴────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_health = pl.read_parquet(data_paths[\"health\"])\n",
    "lf_health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d70d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>date</th><th>status</th><th>occupation</th><th>weekly_hours</th><th>residence_region</th><th>birthday</th></tr><tr><td>str</td><td>date</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>date</td></tr></thead><tbody><tr><td>&quot;E08275&quot;</td><td>2018-10-01</td><td>&quot;employed&quot;</td><td>&quot;engineering&quot;</td><td>35.2</td><td>&quot;island&quot;</td><td>1958-01-03</td></tr><tr><td>&quot;E01592&quot;</td><td>2015-09-01</td><td>&quot;unemployed&quot;</td><td>&quot;transport&quot;</td><td>0.0</td><td>&quot;west&quot;</td><td>1989-02-14</td></tr><tr><td>&quot;E03390&quot;</td><td>2020-05-01</td><td>&quot;sick_leave&quot;</td><td>&quot;finance&quot;</td><td>0.0</td><td>&quot;central&quot;</td><td>1984-03-30</td></tr><tr><td>&quot;E07769&quot;</td><td>2016-11-01</td><td>&quot;sick_leave&quot;</td><td>&quot;finance&quot;</td><td>0.0</td><td>&quot;north&quot;</td><td>1994-06-16</td></tr><tr><td>&quot;E09141&quot;</td><td>2019-02-01</td><td>&quot;self_employed&quot;</td><td>&quot;transport&quot;</td><td>34.7</td><td>&quot;east&quot;</td><td>1993-03-08</td></tr><tr><td>&quot;E07700&quot;</td><td>2023-08-01</td><td>&quot;employed&quot;</td><td>&quot;agriculture&quot;</td><td>40.7</td><td>&quot;south&quot;</td><td>1987-08-08</td></tr><tr><td>&quot;E04750&quot;</td><td>2015-11-01</td><td>&quot;employed&quot;</td><td>&quot;manufacturing&quot;</td><td>39.5</td><td>&quot;island&quot;</td><td>1977-11-16</td></tr><tr><td>&quot;E00464&quot;</td><td>2016-04-01</td><td>&quot;unemployed&quot;</td><td>&quot;IT&quot;</td><td>0.0</td><td>&quot;north&quot;</td><td>1990-12-06</td></tr><tr><td>&quot;E01583&quot;</td><td>2023-09-01</td><td>&quot;self_employed&quot;</td><td>&quot;hospitality&quot;</td><td>36.5</td><td>&quot;west&quot;</td><td>1998-09-07</td></tr><tr><td>&quot;E08483&quot;</td><td>2019-02-01</td><td>&quot;employed&quot;</td><td>&quot;retail&quot;</td><td>36.7</td><td>&quot;central&quot;</td><td>1993-02-02</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "┌───────────┬────────────┬───────────────┬──────────────┬──────────────┬──────────────┬────────────┐\n",
       "│ entity_id ┆ date       ┆ status        ┆ occupation   ┆ weekly_hours ┆ residence_re ┆ birthday   │\n",
       "│ ---       ┆ ---        ┆ ---           ┆ ---          ┆ ---          ┆ gion         ┆ ---        │\n",
       "│ str       ┆ date       ┆ str           ┆ str          ┆ f64          ┆ ---          ┆ date       │\n",
       "│           ┆            ┆               ┆              ┆              ┆ str          ┆            │\n",
       "╞═══════════╪════════════╪═══════════════╪══════════════╪══════════════╪══════════════╪════════════╡\n",
       "│ E08275    ┆ 2018-10-01 ┆ employed      ┆ engineering  ┆ 35.2         ┆ island       ┆ 1958-01-03 │\n",
       "│ E01592    ┆ 2015-09-01 ┆ unemployed    ┆ transport    ┆ 0.0          ┆ west         ┆ 1989-02-14 │\n",
       "│ E03390    ┆ 2020-05-01 ┆ sick_leave    ┆ finance      ┆ 0.0          ┆ central      ┆ 1984-03-30 │\n",
       "│ E07769    ┆ 2016-11-01 ┆ sick_leave    ┆ finance      ┆ 0.0          ┆ north        ┆ 1994-06-16 │\n",
       "│ E09141    ┆ 2019-02-01 ┆ self_employed ┆ transport    ┆ 34.7         ┆ east         ┆ 1993-03-08 │\n",
       "│ E07700    ┆ 2023-08-01 ┆ employed      ┆ agriculture  ┆ 40.7         ┆ south        ┆ 1987-08-08 │\n",
       "│ E04750    ┆ 2015-11-01 ┆ employed      ┆ manufacturin ┆ 39.5         ┆ island       ┆ 1977-11-16 │\n",
       "│           ┆            ┆               ┆ g            ┆              ┆              ┆            │\n",
       "│ E00464    ┆ 2016-04-01 ┆ unemployed    ┆ IT           ┆ 0.0          ┆ north        ┆ 1990-12-06 │\n",
       "│ E01583    ┆ 2023-09-01 ┆ self_employed ┆ hospitality  ┆ 36.5         ┆ west         ┆ 1998-09-07 │\n",
       "│ E08483    ┆ 2019-02-01 ┆ employed      ┆ retail       ┆ 36.7         ┆ central      ┆ 1993-02-02 │\n",
       "└───────────┴────────────┴───────────────┴──────────────┴──────────────┴──────────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_labour = pl.read_parquet(data_paths[\"labour\"])\n",
    "lf_labour.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e15d4",
   "metadata": {},
   "source": [
    "## Sources\n",
    "A `Source` represents a data table(-s) of a specific event type. This could be a hospital admissions registry,\n",
    "an income registry, or a labor market record... you name it.\n",
    "\n",
    "Each `Source` stores the information needed to read and validate that table:\n",
    "1. where it lives on disk,\n",
    "2. which column identifies the entity (e.g. a person, firm, or object),\n",
    "3. which column holds the timestamp, and\n",
    "4. which columns carry categorical or continuous features.\n",
    "\n",
    "`Source` heavily relies on the `pydantic` configuration files: makes it straightforward to define new event types simply by writing \n",
    "a config, without touching any reading or validation logic.\n",
    "\n",
    "**Note**: `Source` makes the first filtering and preprocessing steps by removing rows with empty `enitity_ids` \n",
    "and rows with empty `timestamp_cols` (in case you specified these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2afe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tab2seq.source import Source, SourceConfig, SourceCollection, CategoricalColConfig, ContinuousColConfig, TimestampColConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9fc417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs: 9797\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (40_079, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>entity_id</th><th>date</th><th>diagnosis</th><th>procedure</th><th>department</th><th>cost</th><th>length_of_stay</th></tr><tr><td>str</td><td>date</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;E00001&quot;</td><td>2016-09-15</td><td>&quot;DIAG_J18.1&quot;</td><td>&quot;PROC_CABG&quot;</td><td>&quot;DEPT_gastroenterology&quot;</td><td>7306.17</td><td>2</td></tr><tr><td>&quot;E00001&quot;</td><td>2017-05-25</td><td>&quot;DIAG_E78.0&quot;</td><td>&quot;PROC_XRAY&quot;</td><td>&quot;DEPT_neurology&quot;</td><td>138.65</td><td>1</td></tr><tr><td>&quot;E00001&quot;</td><td>2018-01-18</td><td>&quot;DIAG_E78.0&quot;</td><td>&quot;PROC_MRI&quot;</td><td>&quot;DEPT_general_surgery&quot;</td><td>6704.59</td><td>10</td></tr><tr><td>&quot;E00001&quot;</td><td>2019-11-11</td><td>&quot;DIAG_C34.1&quot;</td><td>&quot;PROC_ECHO&quot;</td><td>&quot;DEPT_general_surgery&quot;</td><td>910.12</td><td>0</td></tr><tr><td>&quot;E00001&quot;</td><td>2020-05-20</td><td>&quot;DIAG_E78.0&quot;</td><td>&quot;PROC_DIALYSIS&quot;</td><td>&quot;DEPT_neurology&quot;</td><td>2266.52</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;E09999&quot;</td><td>2021-11-10</td><td>&quot;DIAG_J96.0&quot;</td><td>&quot;PROC_SPIROMETRY&quot;</td><td>&quot;DEPT_pulmonology&quot;</td><td>3082.13</td><td>1</td></tr><tr><td>&quot;E09999&quot;</td><td>2024-12-15</td><td>&quot;DIAG_I25.1&quot;</td><td>&quot;PROC_DIALYSIS&quot;</td><td>&quot;DEPT_general_surgery&quot;</td><td>1306.49</td><td>1</td></tr><tr><td>&quot;E10000&quot;</td><td>2017-03-02</td><td>&quot;DIAG_S72.0&quot;</td><td>&quot;PROC_ECHO&quot;</td><td>&quot;DEPT_gastroenterology&quot;</td><td>72.14</td><td>3</td></tr><tr><td>&quot;E10000&quot;</td><td>2020-06-10</td><td>&quot;DIAG_E78.0&quot;</td><td>&quot;PROC_SPIROMETRY&quot;</td><td>&quot;DEPT_cardiology&quot;</td><td>75.03</td><td>2</td></tr><tr><td>&quot;E10000&quot;</td><td>2023-03-24</td><td>&quot;DIAG_I21.0&quot;</td><td>&quot;PROC_SPIROMETRY&quot;</td><td>&quot;DEPT_general_surgery&quot;</td><td>532.95</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (40_079, 7)\n",
       "┌───────────┬────────────┬────────────┬────────────────┬────────────────┬─────────┬────────────────┐\n",
       "│ entity_id ┆ date       ┆ diagnosis  ┆ procedure      ┆ department     ┆ cost    ┆ length_of_stay │\n",
       "│ ---       ┆ ---        ┆ ---        ┆ ---            ┆ ---            ┆ ---     ┆ ---            │\n",
       "│ str       ┆ date       ┆ str        ┆ str            ┆ str            ┆ f64     ┆ i64            │\n",
       "╞═══════════╪════════════╪════════════╪════════════════╪════════════════╪═════════╪════════════════╡\n",
       "│ E00001    ┆ 2016-09-15 ┆ DIAG_J18.1 ┆ PROC_CABG      ┆ DEPT_gastroent ┆ 7306.17 ┆ 2              │\n",
       "│           ┆            ┆            ┆                ┆ erology        ┆         ┆                │\n",
       "│ E00001    ┆ 2017-05-25 ┆ DIAG_E78.0 ┆ PROC_XRAY      ┆ DEPT_neurology ┆ 138.65  ┆ 1              │\n",
       "│ E00001    ┆ 2018-01-18 ┆ DIAG_E78.0 ┆ PROC_MRI       ┆ DEPT_general_s ┆ 6704.59 ┆ 10             │\n",
       "│           ┆            ┆            ┆                ┆ urgery         ┆         ┆                │\n",
       "│ E00001    ┆ 2019-11-11 ┆ DIAG_C34.1 ┆ PROC_ECHO      ┆ DEPT_general_s ┆ 910.12  ┆ 0              │\n",
       "│           ┆            ┆            ┆                ┆ urgery         ┆         ┆                │\n",
       "│ E00001    ┆ 2020-05-20 ┆ DIAG_E78.0 ┆ PROC_DIALYSIS  ┆ DEPT_neurology ┆ 2266.52 ┆ 2              │\n",
       "│ …         ┆ …          ┆ …          ┆ …              ┆ …              ┆ …       ┆ …              │\n",
       "│ E09999    ┆ 2021-11-10 ┆ DIAG_J96.0 ┆ PROC_SPIROMETR ┆ DEPT_pulmonolo ┆ 3082.13 ┆ 1              │\n",
       "│           ┆            ┆            ┆ Y              ┆ gy             ┆         ┆                │\n",
       "│ E09999    ┆ 2024-12-15 ┆ DIAG_I25.1 ┆ PROC_DIALYSIS  ┆ DEPT_general_s ┆ 1306.49 ┆ 1              │\n",
       "│           ┆            ┆            ┆                ┆ urgery         ┆         ┆                │\n",
       "│ E10000    ┆ 2017-03-02 ┆ DIAG_S72.0 ┆ PROC_ECHO      ┆ DEPT_gastroent ┆ 72.14   ┆ 3              │\n",
       "│           ┆            ┆            ┆                ┆ erology        ┆         ┆                │\n",
       "│ E10000    ┆ 2020-06-10 ┆ DIAG_E78.0 ┆ PROC_SPIROMETR ┆ DEPT_cardiolog ┆ 75.03   ┆ 2              │\n",
       "│           ┆            ┆            ┆ Y              ┆ y              ┆         ┆                │\n",
       "│ E10000    ┆ 2023-03-24 ┆ DIAG_I21.0 ┆ PROC_SPIROMETR ┆ DEPT_general_s ┆ 532.95  ┆ 0              │\n",
       "│           ┆            ┆            ┆ Y              ┆ urgery         ┆         ┆                │\n",
       "└───────────┴────────────┴────────────┴────────────────┴────────────────┴─────────┴────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_H = Source(config=SourceConfig(\n",
    "    name=\"health\",\n",
    "    filepath=\"synthetic_data/health.parquet\",\n",
    "    id_col=\"entity_id\",\n",
    "    categorical_cols=[\n",
    "        CategoricalColConfig(col_name=\"diagnosis\", prefix=\"DIAG\"),\n",
    "        CategoricalColConfig(col_name=\"procedure\", prefix=\"PROC\"),\n",
    "        CategoricalColConfig(col_name=\"department\", prefix=\"DEPT\"),\n",
    "    ],\n",
    "    continuous_cols=[\n",
    "        ContinuousColConfig(col_name=\"cost\", prefix=\"COST\", n_bins=20, strategy=\"quantile\"),\n",
    "        ContinuousColConfig(col_name=\"length_of_stay\", prefix=\"LOS\", n_bins=20, strategy=\"quantile\"),\n",
    "    ],\n",
    "    output_format=\"parquet\",\n",
    "    timestamp_cols=[\n",
    "        TimestampColConfig(col_name=\"date\", is_primary=True, drop_na=True)\n",
    "    ]\n",
    "))\n",
    "\n",
    "print(\"Number of unique IDs:\", len(source_H.get_entity_ids()))\n",
    "source_H.process(cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8c553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs: 10000\n"
     ]
    }
   ],
   "source": [
    "# or you could define the Source config separately and then create the Source\n",
    "\n",
    "config_L = SourceConfig(\n",
    "    name=\"labour\",\n",
    "    filepath=\"synthetic_data/labour.parquet\",\n",
    "    id_col=\"entity_id\",\n",
    "    categorical_cols=[\n",
    "        CategoricalColConfig(col_name=\"status\", prefix=\"STATUS\"),\n",
    "        CategoricalColConfig(col_name=\"occupation\", prefix=\"OCC\"),\n",
    "        CategoricalColConfig(col_name=\"residence_region\", prefix=\"REGION\"),\n",
    "    ],\n",
    "    continuous_cols=[\n",
    "        ContinuousColConfig(col_name=\"weekly_hours\", prefix=\"WEEKLY_HOURS\")\n",
    "    ],\n",
    "    output_format=\"parquet\",\n",
    "    timestamp_cols=[\n",
    "        TimestampColConfig(col_name=\"date\", is_primary=True, drop_na=True),\n",
    "        TimestampColConfig(col_name=\"birthday\", is_primary=False, drop_na=True),\n",
    "    ],\n",
    ")\n",
    "source_L = Source(config=config_L)\n",
    "\n",
    "print(\"Number of unique IDs:\", len(source_L.get_entity_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0ae9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique entity IDs in collection: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'health': Source(name='health', path=PosixPath('synthetic_data/health.parquet')),\n",
       " 'labour': Source(name='labour', path=PosixPath('synthetic_data/labour.parquet'))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also create a SourceCollection to manage multiple sources together\n",
    "collection = SourceCollection(sources=[source_H, source_L])\n",
    "\n",
    "\n",
    "print(\"All unique entity IDs in collection:\", len(collection.get_all_entity_ids()))\n",
    "#You can get access to the individual sources in the collection by running the following:\n",
    "collection.sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d6afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health: 9797 entities\n",
      "labour: 10000 entities\n"
     ]
    }
   ],
   "source": [
    "# Or you can make collections directly from configs\n",
    "from tab2seq.source import SourceCollection, SourceConfig, CategoricalColConfig, ContinuousColConfig, TimestampColConfig\n",
    "\n",
    "# Define your data sources\n",
    "configs = [\n",
    "    SourceConfig(\n",
    "        name=\"health\",\n",
    "        filepath=\"synthetic_data/health.parquet\",\n",
    "        id_col=\"entity_id\",\n",
    "        categorical_cols=[\n",
    "            CategoricalColConfig(col_name=\"diagnosis\", prefix=\"DIAG\"),\n",
    "            CategoricalColConfig(col_name=\"procedure\", prefix=\"PROC\"),\n",
    "            CategoricalColConfig(col_name=\"department\", prefix=\"DEPT\"),\n",
    "        ],\n",
    "        continuous_cols=[\n",
    "            ContinuousColConfig(col_name=\"cost\", prefix=\"COST\", n_bins=20, strategy=\"quantile\"),\n",
    "            ContinuousColConfig(col_name=\"length_of_stay\", prefix=\"LOS\", n_bins=20, strategy=\"quantile\"),\n",
    "        ],\n",
    "        output_format=\"parquet\",\n",
    "        timestamp_cols=[\n",
    "            TimestampColConfig(col_name=\"date\", is_primary=True, drop_na=True)\n",
    "        ]\n",
    "    ),\n",
    "    SourceConfig(\n",
    "        name=\"labour\",\n",
    "        filepath=\"synthetic_data/labour.parquet\",\n",
    "        id_col=\"entity_id\",\n",
    "        categorical_cols=[\n",
    "            CategoricalColConfig(col_name=\"status\", prefix=\"STATUS\"),\n",
    "            CategoricalColConfig(col_name=\"occupation\", prefix=\"OCC\"),\n",
    "            CategoricalColConfig(col_name=\"residence_region\", prefix=\"REGION\"),\n",
    "        ],\n",
    "        continuous_cols=[\n",
    "            ContinuousColConfig(col_name=\"weekly_hours\", prefix=\"WEEKLY_HOURS\")\n",
    "        ],\n",
    "        output_format=\"parquet\",\n",
    "        timestamp_cols=[\n",
    "            TimestampColConfig(col_name=\"date\", is_primary=True, drop_na=True),\n",
    "            TimestampColConfig(col_name=\"birthday\", is_primary=False, drop_na=True),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create a source collection\n",
    "collection = SourceCollection.from_configs(configs)\n",
    "\n",
    "# Access individual sources\n",
    "health = collection[\"health\"]\n",
    "df = health.read_all()\n",
    "\n",
    "# Or iterate over all sources\n",
    "for source in collection:\n",
    "    print(f\"{source.name}: {len(source.get_entity_ids())} entities\")\n",
    "\n",
    "# Cross-source operations\n",
    "all_entity_ids = collection.get_all_entity_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bc2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tab2seq-dev-mZHLrpIW-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
